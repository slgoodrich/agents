# ICE Scoring Template

## Formula

**ICE Score = (Impact + Confidence + Ease) / 3**

## Scoring Guide

All three components are scored on a scale of **1-10**.

### Impact
How much will this move the needle on your key metric?
- **10** = Transformational impact on key metric
- **8-9** = Significant improvement
- **5-7** = Moderate improvement
- **3-4** = Small improvement
- **1-2** = Minimal impact

### Confidence
How sure are you this will work?
- **10** = Proven approach, strong data, high certainty
- **8-9** = Good data, reasonable certainty
- **5-7** = Some evidence, moderate certainty
- **3-4** = Educated guess, low certainty
- **1-2** = Pure speculation, very uncertain

### Ease
How simple is this to implement?
- **10** = Trivially easy, <1 day
- **8-9** = Very easy, 2-3 days
- **5-7** = Moderate, 1 week
- **3-4** = Somewhat complex, 2-3 weeks
- **1-2** = Very complex, 1+ month

## Scoring Template

| Feature | Impact (1-10) | Confidence (1-10) | Ease (1-10) | ICE Score | Rank |
|---------|---------------|-------------------|-------------|-----------|------|
| Feature A | 8 | 9 | 7 | 8.0 | |
| Feature B | 10 | 5 | 3 | 6.0 | |
| Feature C | 6 | 8 | 9 | 7.7 | |
| Feature D | 4 | 10 | 10 | 8.0 | |
| Feature E | | | | | |

## Example

**Feature: Email Notifications for New Messages**
- **Impact**: 8/10 (drives re-engagement, proven pattern for retention)
- **Confidence**: 9/10 (lots of data showing email works for this use case)
- **Ease**: 7/10 (1 week build - template setup + trigger logic)

**ICE Score = (8 + 9 + 7) / 3 = 8.0**

## When to Use ICE

- **Early-stage products** with limited data (simpler than RICE)
- **Growth experiments** that need quick evaluation
- **Quick prioritization** when you need speed over precision
- **Startup environments** with fast iteration cycles

## Tips

- **Score as a team** - aggregate individual scores or discuss together
- **Timebox scoring** - don't spend hours debating, go with gut + data
- **Use for experiments** - ICE is great for quick tests, less for big bets
- **Combine with strategy** - ensure high-scoring items align with goals
- **Re-score regularly** - impact/ease change as you learn
- **Track accuracy** - did high-ICE items actually work? Calibrate scoring

## ICE vs RICE

**Use ICE when:**
- Limited quantitative data
- Need quick decision
- Early-stage/pre-PMF
- Growth experiments

**Use RICE when:**
- Have user reach data
- Large backlog (20+ items)
- Post-PMF with metrics
- Need defendable priorities

## Next Steps

1. List all features/experiments to prioritize
2. Score each on Impact, Confidence, Ease (1-10 scale)
3. Calculate ICE scores
4. Sort by score (highest to lowest)
5. Validate top 3-5 align with strategy
6. Run experiments or build features
7. Track results and recalibrate scoring
